import os
import argparse
from data_layer.vector_store import vector_store
from data_layer.preprocessor import UXOPreprocessor
from langchain.schema import Document

def import_files(input_dir: str, file_types: list[str], chunk_size: int = 1000, chunk_overlap: int = 200):
    """
    Import t·∫•t c·∫£ file trong th∆∞ m·ª•c v√†o vector store m√† kh√¥ng ghi ƒë√® d·ªØ li·ªáu c≈©
    """
    total_chunks = 0

    # Check/load vector store
    if not vector_store.is_initialized():
        vector_store.load_or_create_vector_store()
        print(f"‚úÖ Vector store ƒë√£ s·∫µn s√†ng!")

    for root, _, files in os.walk(input_dir):
        for file in files:
            if any(file.lower().endswith(ext) for ext in file_types):
                file_path = os.path.join(root, file)
                print(f"\nüìÑ ƒêang x·ª≠ l√Ω: {file_path}")

                try:
                    ids = vector_store.import_file(file_path, chunk_size=chunk_size, chunk_overlap=chunk_overlap)
                    if ids:
                        total_chunks += len(ids)
                except Exception as e:
                    print(f"‚ö†Ô∏è L·ªói khi import {file}: {e}")

    print(f"\nüéØ Ho√†n t·∫•t! T·ªïng c·ªông {total_chunks} chunks ƒë∆∞·ª£c th√™m v√†o vector DB.")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Import PDF/TXT/DOCX v√†o Vector Database m√† kh√¥ng m·∫•t d·ªØ li·ªáu c≈©")
    parser.add_argument("--dir", type=str, required=True, help="Th∆∞ m·ª•c ch·ª©a d·ªØ li·ªáu (PDF/TXT/DOCX)")
    parser.add_argument("--types", type=str, default="pdf,txt,docx", help="Lo·∫°i file (vd: pdf,txt,docx)")
    parser.add_argument("--chunk_size", type=int, default=1000, help="K√≠ch th∆∞·ªõc chunk vƒÉn b·∫£n")
    parser.add_argument("--chunk_overlap", type=int, default=200, help="Overlap gi·ªØa c√°c chunk")
    args = parser.parse_args()

    file_types = [ext.strip().lower() for ext in args.types.split(",")]
    import_files(args.dir, file_types, chunk_size=args.chunk_size, chunk_overlap=args.chunk_overlap)
