setting lib: pip install -r requirements.txt

data_layer
crawler.py (thu tháº­p dá»¯ liá»‡u tá»« web, file, API)
     â†“
preprocessor.py (lÃ m sáº¡ch, chuáº©n hÃ³a, chia nhá» vÄƒn báº£n)
     â†“
vector_store.py (táº¡o embedding, lÆ°u vÃ o FAISS/Qdrant/Chroma) -> run file to test: python -m data_layer.run
     â†“
retrieval_qa.py (dÃ¹ng Ä‘á»ƒ truy váº¥n RAG + LLM)

chroma_db: thÆ° má»¥c lÆ°u trá»¯ cÆ¡ sá»Ÿ dá»¯ liá»‡u vector (vector database)

chroma.sqlite3 â†’ database chÃ­nh (lÆ°u metadata, collections, mappings giá»¯a doc-id vÃ  embedding).

ThÆ° má»¥c cÃ³ tÃªn nhÆ° cf687ce7-0cb1-4842-841c-a884505e6b9d â†’ chÃ­nh lÃ  faiss/HNSW index Ä‘Æ°á»£c Chroma táº¡o ra Ä‘á»ƒ lÆ°u vector embeddings.

data_level0.bin, header.bin, length.bin, link_lists.bin â†’ lÃ  cÃ¡c file nhá»‹ phÃ¢n lÆ°u Ä‘á»“ thá»‹ HNSW index.

index_metadata.pickle â†’ metadata cho index.

######################################
ai_core
1. nlu_processor.py

Má»¥c Ä‘Ã­ch: Xá»­ lÃ½ NLU (Natural Language Understanding) cho chatbot.

Chá»©c nÄƒng chÃ­nh:

PhÃ¡t hiá»‡n intent cá»§a ngÆ°á»i dÃ¹ng (vÃ­ dá»¥: há»i Ä‘á»‹nh nghÄ©a, hÆ°á»›ng dáº«n an toÃ n, bÃ¡o cÃ¡o UXOâ€¦).

TrÃ­ch xuáº¥t entities (thá»±c thá»ƒ) tá»« cÃ¢u há»i (vÃ­ dá»¥: location, loáº¡i UXO, hÃ nh Ä‘á»™ng).

Káº¿t há»£p intent detection vÃ  entity extraction thÃ nh má»™t hÃ m duy nháº¥t process_nlu.

2. memory_manager.py

Má»¥c Ä‘Ã­ch: Quáº£n lÃ½ bá»™ nhá»› há»™i thoáº¡i cho tá»«ng session ngÆ°á»i dÃ¹ng.

Chá»©c nÄƒng chÃ­nh:

LÆ°u giá»¯ ngá»¯ cáº£nh cÃ¡c tin nháº¯n gáº§n Ä‘Ã¢y (ConversationBufferWindowMemory) Ä‘á»ƒ há»— trá»£ multi-turn conversation.

Láº¥y, lÆ°u vÃ  xÃ³a memory theo session_id.

3. retrieval_qa.py

Má»¥c Ä‘Ã­ch: Xá»­ lÃ½ QA dá»±a trÃªn tÃ i liá»‡u (retrieval-based QA) cho cÃ¡c intent khÃ¡c nhau.

Chá»©c nÄƒng chÃ­nh:

Khá»Ÿi táº¡o cÃ¡c chain QA vá»›i prompt template khÃ¡c nhau cho tá»«ng intent (vÃ­ dá»¥: definition, safety_advice).

TÃ­ch há»£p vector store Ä‘á»ƒ truy xuáº¥t thÃ´ng tin tá»« tÃ i liá»‡u UXO Ä‘Ã£ index.

Cung cáº¥p hÃ m get_response tráº£ lá»i cÃ¢u há»i dá»±a trÃªn intent vÃ  ngÃ´n ngá»¯.

4. llm_chain.py

Má»¥c Ä‘Ã­ch: Khá»Ÿi táº¡o vÃ  cáº¥u hÃ¬nh LLM (Language Model) cho chatbot.

Chá»©c nÄƒng chÃ­nh:

Táº¡o instance cá»§a GeminiLLM (hoáº·c OpenAI/LLM khÃ¡c) Ä‘á»ƒ sá»­ dá»¥ng trong cÃ¡c chain NLU, QA.

CÃ³ thá»ƒ Ä‘áº·t cÃ¡c tham sá»‘ nhÆ° temperature, max tokens, model name Ä‘á»ƒ Ä‘iá»u chá»‰nh hÃ nh vi LLM.

run: python -m tests.run_ai_core

setup version: python3.10 -m venv venv310
kÃ­ch hoáº¡t: .\venv310\Scripts\Activate.ps1

## ğŸ“‚ API Module

- **`api/schemas.py`**  
  Äá»‹nh nghÄ©a cÃ¡c **Pydantic models** cho request/response cá»§a API (vÃ­ dá»¥: `ChatRequest`, `QAResponse`, `ErrorResponse`).  
  â†’ GiÃºp chuáº©n hÃ³a dá»¯ liá»‡u trao Ä‘á»•i giá»¯a client â†” server, há»— trá»£ validation vÃ  tá»± Ä‘á»™ng sinh tÃ i liá»‡u API.

- **`api/main.py`**  
  File **entrypoint FastAPI** cá»§a há»‡ thá»‘ng.  
  â†’ Khá»Ÿi táº¡o á»©ng dá»¥ng, load cÃ¡c module AI (LLM, NLU, QA, memory) vÃ  Ä‘á»‹nh nghÄ©a cÃ¡c **endpoint** chÃ­nh:  
    - `/` â€“ Health check nhanh  
    - `/health` â€“ Tráº¡ng thÃ¡i chi tiáº¿t cÃ¡c module  
    - `/ask` â€“ Äáº·t cÃ¢u há»i vÃ  nháº­n cÃ¢u tráº£ lá»i tá»« chatbot  
    - `/memory/{session_id}` â€“ XÃ³a bá»™ nhá»› há»™i thoáº¡i theo session
    
app/main.py
 app/
â”‚   â”‚â”€â”€ main.py          # FastAPI entrypoint
â”‚   â”‚â”€â”€ schema.py        # Pydantic models
run fastapi: uvicorn app.main:app --reload

Truy cáº­p API

Health check: http://localhost:8000/

API docs (Swagger UI): http://localhost:8000/docs

Alternative docs (ReDoc): http://localhost:8000/redoc

frontend
before run frontend, we need to run backend first
run frontend: cd: frontend/streamlit run app.py