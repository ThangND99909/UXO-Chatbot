from langchain.prompts import PromptTemplate
from typing import Dict, Any, List
from data_layer.hotline_manager import HotlineManager
from ai_core.nlu_processor import NLUProcessor
from ai_core.memory_manager import UXOMemoryManager
import traceback

class UXORetrievalQA:
    def __init__(self, llm, vector_store):
        self.llm = llm
        self.vector_store = vector_store
        self.hotline_manager = HotlineManager()
        self.memory_manager = UXOMemoryManager()
        # ‚úÖ N·ªëi memory_manager v·ªõi NLU
        self.nlu_processor = NLUProcessor(llm, memory_manager=self.memory_manager)
        self.setup_qa_chains()
    
    def setup_qa_chains(self):
        # ================= DEFINITION PROMPT =================
        definition_template = """
            B·∫°n l√† tr·ª£ l√Ω ·∫£o chuy√™n gia v·ªÅ bom m√¨n v√† v·∫≠t n·ªï ch∆∞a n·ªï (UXO) t·∫°i Vi·ªát Nam.
            D·ª±a tr√™n ng·ªØ c·∫£nh d∆∞·ªõi ƒë√¢y, h√£y tr·∫£ l·ªùi c√¢u h·ªèi b·∫±ng ng√¥n ng·ªØ {language}.

            L·ªäCH S·ª¨ CHAT G·∫¶N ƒê√ÇY:
            {chat_history}

            TH√îNG TIN TRA C·ª®U:
            {context}

            C√¢u h·ªèi: {question}

            H√£y tr·∫£ l·ªùi ng·∫Øn g·ªçn, ch√≠nh x√°c v√† h·ªØu √≠ch. N·∫øu kh√¥ng bi·∫øt c√¢u tr·∫£ l·ªùi, h√£y n√≥i kh√¥ng bi·∫øt.
            Tr·∫£ l·ªùi b·∫±ng ng√¥n ng·ªØ {language}:
            """
        self.definition_prompt = PromptTemplate(
            template=definition_template,
            input_variables=["context", "question", "language", "chat_history"]
        )

        # ================= SAFETY PROMPT =================
        safety_template = """
        B·∫°n l√† chuy√™n gia h∆∞·ªõng d·∫´n an to√†n v·ªÅ bom m√¨n v√† v·∫≠t n·ªï ch∆∞a n·ªï (UXO).
        D·ª±a tr√™n ng·ªØ c·∫£nh d∆∞·ªõi ƒë√¢y, h√£y tr·∫£ l·ªùi c√¢u h·ªèi b·∫±ng ng√¥n ng·ªØ {language}.
        
        L·ªäCH S·ª¨ CHAT G·∫¶N ƒê√ÇY:
        {chat_history}
        
        TH√îNG TIN TRA C·ª®U:
        {context}
        
        ‚ö†Ô∏è QUAN TR·ªåNG: 
        - Lu√¥n nh·∫•n m·∫°nh v√†o vi·ªác KH√îNG CH·∫†M v√†o v·∫≠t nghi ng·ªù.
        - G·ªçi ngay hotline c∆° quan ch·ª©c nƒÉng t·∫°i ƒë·ªãa ph∆∞∆°ng.
        
        C√¢u h·ªèi: {question}
        
        H√£y tr·∫£ l·ªùi r√µ r√†ng, t·ª´ng b∆∞·ªõc v√† an to√†n. 
        Lu√¥n cung c·∫•p s·ªë hotline n·∫øu c√≥.
        Tr·∫£ l·ªùi b·∫±ng ng√¥n ng·ªØ {language}:
        """
        self.safety_prompt = PromptTemplate(
            template=safety_template,
            input_variables=["context", "question", "language", "chat_history"]
        )

        # ================= LOCATION PROMPT =================
        location_template = """
        B·∫°n l√† chuy√™n gia v·ªÅ th√¥ng tin ƒë·ªãa ƒëi·ªÉm li√™n quan ƒë·∫øn bom m√¨n v√† UXO t·∫°i Vi·ªát Nam.
        D·ª±a tr√™n ng·ªØ c·∫£nh d∆∞·ªõi ƒë√¢y, h√£y tr·∫£ l·ªùi c√¢u h·ªèi b·∫±ng ng√¥n ng·ªØ {language}.

        L·ªäCH S·ª¨ CHAT G·∫¶N ƒê√ÇY:
        {chat_history}

        TH√îNG TIN TRA C·ª®U:
        {context}

        C√¢u h·ªèi: {question}

        H√£y cung c·∫•p th√¥ng tin ch√≠nh x√°c v·ªÅ ƒë·ªãa ƒëi·ªÉm, khu v·ª±c, v√† c√°c th√¥ng tin li√™n quan.
        N·∫øu c√≥ s·ªë hotline c·ª• th·ªÉ cho khu v·ª±c, h√£y cung c·∫•p.
        Tr·∫£ l·ªùi b·∫±ng ng√¥n ng·ªØ {language}:
        """
        self.location_prompt = PromptTemplate(
            template=location_template,
            input_variables=["context", "question", "language", "chat_history"]
        )

        # T·∫°o retriever
        self.retriever = self.vector_store.as_retriever()

    # ================= AI-PROMPT SELECTION =================
    def get_response(self, question: str, intent: str, session_id: str = "default",
                 language: str = "vi", enriched_text: str = None) -> str:
        try:
            chat_history = self.memory_manager.get_chat_history(session_id)
            last_intent = self.memory_manager.get_last_intent(session_id)
            last_question = self.memory_manager.get_last_question(session_id)
            effective_query = enriched_text if enriched_text else question

            print(f"üß† CONTEXT AWARE: last_intent='{last_intent}', current_intent='{intent}', "
                f"question='{question}', effective_query='{effective_query}'")

            # L·∫•y tin nh·∫Øn cu·ªëi c·ªßa assistant
            last_assistant_msg = ""
            try:
                msgs = self.memory_manager.get_messages(session_id)
                for m in reversed(msgs):
                    if getattr(m, "type", "") != "human":
                        last_assistant_msg = getattr(m, "content", "")
                        break
            except Exception:
                pass

            last_assistant_lc = (last_assistant_msg or "").lower()
            awaiting_hotline = (
                "b·∫°n mu·ªën h·ªèi s·ªë hotline" in last_assistant_lc
                or "s·ªë hotline ·ªü khu v·ª±c n√†o" in last_assistant_lc
            )

            # ‚úÖ Case 1: user h·ªèi tr·ª±c ti·∫øp
            if intent == "ask_hotline" or self._is_hotline_question(effective_query):
                print("üîç Hotline request (direct)")
                response = self.process_hotline_request(effective_query, language, session_id)
                self.memory_manager.save_context(session_id, question, response, "ask_hotline")
                return response

            # ‚úÖ Case 2: user tr·∫£ l·ªùi theo ng·ªØ c·∫£nh (bot v·ª´a h·ªèi t·ªânh)
            if last_intent == "ask_hotline" or awaiting_hotline:
                print("‚ö° Hotline follow-up (context aware)")
                full_query = f"{last_question} {question}"
                response = self.process_hotline_request(full_query, language, session_id)
                self.memory_manager.save_context(session_id, question, response, "ask_hotline")
                return response

            # ‚úÖ C√°c intent kh√°c ‚Üí d√πng RAG
            print("üîç Processing with RAG for non-hotline intent")
            response = self._process_rag_intent(effective_query, intent, session_id, language, chat_history)
            effective_intent = intent or "general"
            self.memory_manager.save_context(session_id, question, response, effective_intent)
            return response

        except Exception as e:
            print(f"‚ùå L·ªói khi x·ª≠ l√Ω QA: {str(e)}")
            self.memory_manager.save_context(session_id, question, "L·ªói h·ªá th·ªëng", "error")
            return "Xin l·ªói, t√¥i g·∫∑p s·ª± c·ªë k·ªπ thu·∫≠t. Vui l√≤ng th·ª≠ l·∫°i sau."

    def _is_hotline_follow_up(self, question: str) -> bool:
        question_lower = question.lower().strip()
        hotline_keywords = ["hotline", "s·ªë ƒëi·ªán tho·∫°i", "li√™n h·ªá", "s·ªë m√°y", "ƒëi·ªán tho·∫°i", "phone", "g·ªçi"]
        if any(keyword in question_lower for keyword in hotline_keywords):
            return False
        location_keywords = ["qu·∫£ng b√¨nh", "quang binh", "qb", 
                             "qu·∫£ng tr·ªã", "quang tri", "qt",
                             "th·ª´a thi√™n hu·∫ø", "thua thien hue", "hu·∫ø", "hue", "tth",
                             "ƒë√† n·∫µng", "da nang", "dn",
                             "qu·∫£ng nam", "quang nam", "qn",
                             "ngh·ªá an", "nghe an", "na",
                             "h√† tƒ©nh", "ha tinh", "ht",
                             "thanh h√≥a", "thanh hoa", "th"]
        has_location = any(loc in question_lower for loc in location_keywords)
        is_short = len(question_lower.split()) <= 5
        return has_location and is_short

    def _is_hotline_question(self, question: str) -> bool:
        question_lower = question.lower()
        hotline_keywords = ["hotline", "s·ªë ƒëi·ªán tho·∫°i", "li√™n h·ªá", "s·ªë m√°y", "ƒëi·ªán tho·∫°i", "phone", "g·ªçi", "ƒë∆∞·ªùng d√¢y n√≥ng"]
        return any(keyword in question_lower for keyword in hotline_keywords)

    def _process_rag_intent(self, question: str, intent: str, session_id: str, language: str, chat_history: str) -> str:
        try:
            # ‚úÖ enrich cho c√¢u h·ªèi "·ªü ƒë√¢u"
            enriched_query = f"ƒê·ªãa ƒëi·ªÉm: {question}" if "·ªü ƒë√¢u" in question.lower() else question
            docs = self.retriever.get_relevant_documents(enriched_query)
            if not docs:
                return "‚ùå T√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan trong d·ªØ li·ªáu. B·∫°n c√≥ mu·ªën h·ªèi l·∫°i chi ti·∫øt h∆°n kh√¥ng?"
            context = "\n".join([doc.page_content for doc in docs])

            prompt_mapping = {
                "definition": self.definition_prompt,
                "safety_advice": self.safety_prompt,
                "location_info": self.location_prompt,
                "report_uxo": self.safety_prompt,
                "general": self.definition_prompt
            }
            effective_intent = intent or "general"
            prompt = prompt_mapping.get(effective_intent, self.definition_prompt)

            formatted_prompt = prompt.format(
                context=context,
                question=question,
                language=language,
                chat_history=chat_history
            )

            # ‚úÖ Fix invoke ‚Üí fallback predict
            if hasattr(self.llm, "invoke"):
                response = self.llm.invoke(formatted_prompt).strip()
            else:
                response = self.llm.predict(formatted_prompt).strip()
            return response

        except Exception as e:
            print(f"‚ùå L·ªói khi x·ª≠ l√Ω RAG: {str(e)}")
            print(traceback.format_exc())
            return "Xin l·ªói, t√¥i g·∫∑p s·ª± c·ªë khi t√¨m th√¥ng tin. Vui l√≤ng th·ª≠ l·∫°i sau."

    def extract_location_manual(self, question: str) -> List[str]:
        question_lower = question.lower()
        location_mapping = {
            "qu·∫£ng b√¨nh": "quang_binh", "quang binh": "quang_binh", "qb": "quang_binh",
            "qu·∫£ng tr·ªã": "quang_tri", "quang tri": "quang_tri", "qt": "quang_tri",
            "th·ª´a thi√™n hu·∫ø": "thua_thien_hue", "thua thien hue": "thua_thien_hue", 
            "hu·∫ø": "thua_thien_hue", "hue": "thua_thien_hue", "tth": "thua_thien_hue",
            "ƒë√† n·∫µng": "da_nang", "da nang": "da_nang", "dn": "da_nang",
            "qu·∫£ng nam": "quang_nam", "quang nam": "quang_nam", "qn": "quang_nam",
            "ngh·ªá an": "nghe_an", "nghe an": "nghe_an", "na": "nghe_an",
            "h√† tƒ©nh": "ha_tinh", "ha tinh": "ha_tinh", "ht": "ha_tinh",
            "thanh h√≥a": "thanh_hoa", "thanh hoa": "thanh_hoa", "th": "thanh_hoa"
        }
        return [loc for key, loc in location_mapping.items() if key in question_lower]

    def process_hotline_request(self, question: str, language: str, session_id: str = "default") -> str:
        print(f"üîç Processing hotline request: '{question}'")
        try:
            nlu_result = self.nlu_processor.extract_entities(question, language)
            locations = nlu_result["entities"].get("location", [])
            if not locations:
                locations = self.extract_location_manual(question)

            for location in locations:
                hotline = self.hotline_manager.get_hotline(location)
                if hotline and "Xin l·ªói" not in hotline and "kh√¥ng c√≥" not in hotline.lower():
                    return f"üìû S·ªë hotline x·ª≠ l√Ω bom m√¨n t·∫°i {location.replace('_', ' ').title()} l√†: {hotline}"

            if not locations:
                return ("‚ùì B·∫°n mu·ªën h·ªèi s·ªë hotline ·ªü khu v·ª±c n√†o? "
                        "(V√≠ d·ª•: Qu·∫£ng B√¨nh, Qu·∫£ng Tr·ªã, Hu·∫ø, ƒê√† N·∫µng, Qu·∫£ng Nam, Ngh·ªá An)")
            return f"‚ùå Xin l·ªói, t√¥i kh√¥ng c√≥ th√¥ng tin hotline cho khu v·ª±c {locations[0]}."
        except Exception as e:
            print(f"‚ùå L·ªói khi x·ª≠ l√Ω hotline: {str(e)}")
            print(traceback.format_exc())
            return "Xin l·ªói, t√¥i g·∫∑p s·ª± c·ªë khi t√¨m s·ªë hotline. Vui l√≤ng th·ª≠ l·∫°i sau."
