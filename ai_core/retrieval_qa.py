from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from typing import Dict, Any
from data_layer.hotline_manager import HotlineManager

class UXORetrievalQA:
    def __init__(self, llm, vector_store):
        self.llm = llm
        self.vector_store = vector_store
        self.hotline_manager = HotlineManager()
        self.setup_qa_chains()
    
    def setup_qa_chains(self):
        # ================= DEFINITION PROMPT =================
        definition_template = """
            B·∫°n l√† tr·ª£ l√Ω ·∫£o chuy√™n gia v·ªÅ bom m√¨n v√† v·∫≠t n·ªï ch∆∞a n·ªï (UXO) t·∫°i Vi·ªát Nam.
            D·ª±a tr√™n ng·ªØ c·∫£nh d∆∞·ªõi ƒë√¢y, h√£y tr·∫£ l·ªùi c√¢u h·ªèi b·∫±ng ng√¥n ng·ªØ {language}.

            Ng·ªØ c·∫£nh:
            {context}

            C√¢u h·ªèi: {question}

            H√£y tr·∫£ l·ªùi ng·∫Øn g·ªçn, ch√≠nh x√°c v√† h·ªØu √≠ch. N·∫øu kh√¥ng bi·∫øt c√¢u tr·∫£ l·ªùi, h√£y n√≥i kh√¥ng bi·∫øt.
            Tr·∫£ l·ªùi b·∫±ng ng√¥n ng·ªØ {language}:
            """
        self.definition_prompt = PromptTemplate(
            template=definition_template,
            input_variables=["context", "question", "language"]
        )

        # ================= SAFETY PROMPT =================
        safety_template = """
        B·∫°n l√† chuy√™n gia h∆∞·ªõng d·∫´n an to√†n v·ªÅ bom m√¨n v√† v·∫≠t n·ªï ch∆∞a n·ªï (UXO).
        D·ª±a tr√™n ng·ªØ c·∫£nh d∆∞·ªõi ƒë√¢y, h√£y tr·∫£ l·ªùi c√¢u h·ªèi b·∫±ng ng√¥n ng·ªØ {language}.
        
        ‚ö†Ô∏è QUAN TR·ªåNG: 
        - Lu√¥n nh·∫•n m·∫°nh v√†o vi·ªác KH√îNG CH·∫†M v√†o v·∫≠t nghi ng·ªù.
        - G·ªçi ngay hotline c∆° quan ch·ª©c nƒÉng t·∫°i ƒë·ªãa ph∆∞∆°ng.
        
        Ng·ªØ c·∫£nh:
        {context}
        
        C√¢u h·ªèi: {question}
        
        H√£y tr·∫£ l·ªùi r√µ r√†ng, t·ª´ng b∆∞·ªõc v√† an to√†n. 
        Lu√¥n cung c·∫•p s·ªë hotline n·∫øu c√≥.
        Tr·∫£ l·ªùi b·∫±ng ng√¥n ng·ªØ {language}:
        """
        self.safety_prompt = PromptTemplate(
            template=safety_template,
            input_variables=["context", "question", "language"]
        )

        # ================= LOCATION PROMPT =================
        location_template = """
        B·∫°n l√† chuy√™n gia v·ªÅ th√¥ng tin ƒë·ªãa ƒëi·ªÉm li√™n quan ƒë·∫øn bom m√¨n v√† UXO t·∫°i Vi·ªát Nam.
        D·ª±a tr√™n ng·ªØ c·∫£nh d∆∞·ªõi ƒë√¢y, h√£y tr·∫£ l·ªùi c√¢u h·ªèi b·∫±ng ng√¥n ng·ªØ {language}.

        Ng·ªØ c·∫£nh:
        {context}

        C√¢u h·ªèi: {question}

        H√£y cung c·∫•p th√¥ng tin ch√≠nh x√°c v·ªÅ ƒë·ªãa ƒëi·ªÉm, khu v·ª±c, v√† c√°c th√¥ng tin li√™n quan.
        N·∫øu c√≥ s·ªë hotline c·ª• th·ªÉ cho khu v·ª±c, h√£y cung c·∫•p.
        Tr·∫£ l·ªùi b·∫±ng ng√¥n ng·ªØ {language}:
        """
        self.location_prompt = PromptTemplate(
            template=location_template,
            input_variables=["context", "question", "language"]
        )

        # T·∫°o retriever
        self.retriever = self.vector_store.as_retriever()

    # ================= AI-PROMPT SELECTION =================
    def get_response(self, question: str, intent: str, language: str = "vi") -> str:
        try:
            # ‚úÖ N·∫øu l√† hotline th√¨ x·ª≠ l√Ω ri√™ng, kh√¥ng c·∫ßn retriever
            if intent == "ask_hotline":
                from ai_core.nlu_processor import NLUProcessor
                nlu = NLUProcessor(self.llm)
                nlu_result = nlu.extract_entities(question, language)
                locations = nlu_result["entities"].get("location", [])
                if locations:
                    return self.hotline_manager.get_hotline(locations[0])
                else:
                    return "B·∫°n mu·ªën h·ªèi s·ªë hotline ·ªü khu v·ª±c n√†o?"

            docs = self.retriever.get_relevant_documents(question)
            context = "\n".join([doc.page_content for doc in docs])
            
            # Prompt ƒë·ªÉ LLM t·ª± ch·ªçn template ph√π h·ª£p
            selector_prompt = f"""
            Ph√¢n t√≠ch intent v√† ch·ªçn template ph√π h·ª£p:
            Intent: {intent}
            C√¢u h·ªèi: {question}
            
            C√°c template c√≥ s·∫µn:
            - definition_prompt: cho c√¢u h·ªèi v·ªÅ ƒë·ªãnh nghƒ©a, th√¥ng tin chung, kh√°i ni·ªám
            - safety_prompt: cho c√¢u h·ªèi an to√†n, kh·∫©n c·∫•p, hotline, h∆∞·ªõng d·∫´n h√†nh ƒë·ªông
            - location_prompt: cho c√¢u h·ªèi v·ªÅ ƒë·ªãa ƒëi·ªÉm, khu v·ª±c, ƒë·ªãa b√†n
            
            Ch·ªâ tr·∫£ v·ªÅ t√™n template (definition_prompt, safety_prompt, ho·∫∑c location_prompt)
            Kh√¥ng th√™m b·∫•t k·ª≥ text n√†o kh√°c.
            """
            
            # LLM ch·ªçn template
            selected_template = self.llm.invoke(selector_prompt).strip().lower()
            print(f"üîç AI selected template: {selected_template}")  # Debug
            
            # Map ƒë·∫øn prompt th·ª±c t·∫ø - TH√äM T·∫§T C·∫¢ PROMPTS
            prompt_mapping = {
                "definition_prompt": self.definition_prompt,
                "safety_prompt": self.safety_prompt,
                "location_prompt": self.location_prompt,
            }
            
            # Fallback n·∫øu template kh√¥ng t·ªìn t·∫°i
            prompt = prompt_mapping.get(selected_template, self.safety_prompt)
            
            formatted_prompt = prompt.format(
                context=context,
                question=question,
                language=language
            )
            
            response = self.llm.invoke(formatted_prompt)
            return response.strip()
            
        except Exception as e:
            return f"‚ùå L·ªói khi x·ª≠ l√Ω QA: {e}"

    # ================= PH∆Ø∆†NG TH·ª®C D·ª∞ PH√íNG =================
    def get_response_fallback(self, question: str, intent: str, language: str = "vi") -> str:
        """Ph∆∞∆°ng th·ª©c fallback ƒë∆°n gi·∫£n n·∫øu AI selection g·∫∑p l·ªói"""
        try:
            docs = self.retriever.get_relevant_documents(question)
            context = "\n".join([doc.page_content for doc in docs])
            
            # Logic ch·ªçn prompt ƒë∆°n gi·∫£n
            if "hotline" in intent or "report" in intent or "emergency" in intent or "safety" in intent:
                prompt = self.safety_prompt
            elif "location" in intent or "area" in intent or "where" in intent:
                prompt = self.location_prompt
            else:
                prompt = self.definition_prompt
            
            formatted_prompt = prompt.format(
                context=context,
                question=question,
                language=language
            )
            
            response = self.llm.invoke(formatted_prompt)
            return response.strip()
            
        except Exception as e:
            return f"‚ùå L·ªói khi x·ª≠ l√Ω QA: {e}"